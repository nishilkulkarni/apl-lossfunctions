{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-kh-zamu0xKV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yvrqcer2j7R",
        "outputId": "e2a55504-99c4-4f3e-8ba0-f584f0a2da82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CIFAR10', 'CIFAR100', 'CLEVRClassification', 'CREStereo', 'Caltech101', 'Caltech256', 'CarlaStereo', 'CelebA', 'Cityscapes', 'CocoCaptions', 'CocoDetection', 'Country211', 'DTD', 'DatasetFolder', 'EMNIST', 'ETH3DStereo', 'EuroSAT', 'FER2013', 'FGVCAircraft', 'FakeData', 'FallingThingsStereo', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'Flowers102', 'FlyingChairs', 'FlyingThings3D', 'Food101', 'GTSRB', 'HD1K', 'HMDB51', 'INaturalist', 'ImageFolder', 'ImageNet', 'Imagenette', 'InStereo2k', 'KMNIST', 'Kinetics', 'Kitti', 'Kitti2012Stereo', 'Kitti2015Stereo', 'KittiFlow', 'LFWPairs', 'LFWPeople', 'LSUN', 'LSUNClass', 'MNIST', 'Middlebury2014Stereo', 'MovingMNIST', 'Omniglot', 'OxfordIIITPet', 'PCAM', 'PhotoTour', 'Places365', 'QMNIST', 'RenderedSST2', 'SBDataset', 'SBU', 'SEMEION', 'STL10', 'SUN397', 'SVHN', 'SceneFlowStereo', 'Sintel', 'SintelStereo', 'StanfordCars', 'UCF101', 'USPS', 'VOCDetection', 'VOCSegmentation', 'VisionDataset', 'WIDERFace', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_optical_flow', '_stereo_matching', 'caltech', 'celeba', 'cifar', 'cityscapes', 'clevr', 'coco', 'country211', 'dtd', 'eurosat', 'fakedata', 'fer2013', 'fgvc_aircraft', 'flickr', 'flowers102', 'folder', 'food101', 'gtsrb', 'hmdb51', 'imagenet', 'imagenette', 'inaturalist', 'kinetics', 'kitti', 'lfw', 'lsun', 'mnist', 'moving_mnist', 'omniglot', 'oxford_iiit_pet', 'pcam', 'phototour', 'places365', 'rendered_sst2', 'sbd', 'sbu', 'semeion', 'stanford_cars', 'stl10', 'sun397', 'svhn', 'ucf101', 'usps', 'utils', 'video_utils', 'vision', 'voc', 'widerface']\n"
          ]
        }
      ],
      "source": [
        "print(dir(datasets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P3ldOdct_2ub"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2bywFBKGnin",
        "outputId": "a4a1dfdd-5023-45b7-f1f0-9cc025bc9b19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIiyG5gY29fQ",
        "outputId": "732cef9d-8a62-4a88-8448-6eb956c775cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 61505536/170498071 [01:38<02:55, 622786.84it/s] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m transform_train \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),  \u001b[38;5;66;03m# 50% chance to flip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomAffine(degrees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, translate\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)),  \u001b[38;5;66;03m# Width/height shift by 10%\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      6\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[1;32m      7\u001b[0m ])\n\u001b[1;32m      9\u001b[0m transform_test \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     10\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     11\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])\n\u001b[1;32m     12\u001b[0m ])\n\u001b[0;32m---> 14\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,transform\u001b[38;5;241m=\u001b[39mtransform_train)\n\u001b[1;32m     15\u001b[0m dtest \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,transform\u001b[38;5;241m=\u001b[39mtransform_test)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/cifar.py:139\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m download_and_extract_archive(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, md5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgz_md5)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/utils.py:378\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    376\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 378\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[1;32m    380\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/utils.py:140\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 140\u001b[0m     _urlretrieve(url, fpath)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/utils.py:44\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 44\u001b[0m         _save_response_content(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: response\u001b[38;5;241m.\u001b[39mread(chunk_size), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), filename, length\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/utils.py:33\u001b[0m, in \u001b[0;36m_save_response_content\u001b[0;34m(content, destination, length)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_response_content\u001b[39m(\n\u001b[1;32m     28\u001b[0m     content: Iterator[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m     29\u001b[0m     destination: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     30\u001b[0m     length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(destination, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m content:\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     36\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/utils.py:44\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m---> 44\u001b[0m         _save_response_content(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: response\u001b[38;5;241m.\u001b[39mread(chunk_size), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), filename, length\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1253\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1252\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define data augmentation transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # 50% chance to flip\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Width/height shift by 10%\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dtrain = datasets.CIFAR10(root='data',download=True,train=True,transform=transform_train)\n",
        "dtest = datasets.CIFAR10(root='data',download=True,train=False,transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwdudUYL3hck",
        "outputId": "a5bc8157-e891-4861-95a6-3321f71d907e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Length: 50000\n",
            "Test Dataset Length: 10000\n",
            "Sample Data Type: <class 'tuple'>\n",
            "Image Shape: torch.Size([3, 32, 32])\n",
            "Label: 6\n",
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "# View dataset properties\n",
        "print(f\"Train Dataset Length: {len(dtrain)}\")\n",
        "print(f\"Test Dataset Length: {len(dtest)}\")\n",
        "print(f\"Sample Data Type: {type(dtrain[0])}\")\n",
        "\n",
        "# Access first sample\n",
        "image, label = dtrain[0]\n",
        "print(f\"Image Shape: {image.shape}\")  # (C, H, W) format\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# Check class labels\n",
        "print(f\"Classes: {dtrain.classes if hasattr(dtrain, 'classes') else 'No class labels available'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2lBqxF64Nh3",
        "outputId": "e1f2cd4c-f3a2-4be5-e80c-0bd314902771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(dtrain, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(dtest, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GWZt_Oze7UH6"
      },
      "outputs": [],
      "source": [
        "class CNN8(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN8, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(512 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "\n",
        "        x = self.relu(self.conv5(x))\n",
        "        x = self.pool(self.relu(self.conv6(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CnTrpMTxlxv4"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CrossEntropy, self).__init__()\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        return self.ce_loss(pred, labels)\n",
        "\n",
        "\n",
        "class ReverseCrossEntropy(nn.Module):\n",
        "    def __init__(self, num_classes=10, scale=1.0):\n",
        "        super(ReverseCrossEntropy, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        pred = torch.clamp(pred, min=1e-7, max=1.0)\n",
        "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
        "        label_one_hot = torch.clamp(label_one_hot, min=1e-4, max=1.0)\n",
        "        rce = (-1*torch.sum(pred * torch.log(label_one_hot), dim=1))\n",
        "        return self.scale * rce.mean()\n",
        "\n",
        "\n",
        "class NormalizedReverseCrossEntropy(nn.Module):\n",
        "    def __init__(self, num_classes=10, scale=1.0):\n",
        "        super(NormalizedReverseCrossEntropy, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        pred = torch.clamp(pred, min=1e-7, max=1.0)\n",
        "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
        "        label_one_hot = torch.clamp(label_one_hot, min=1e-4, max=1.0)\n",
        "        normalizor = 1 / 4 * (self.num_classes - 1)\n",
        "        rce = (-1*torch.sum(pred * torch.log(label_one_hot), dim=1))\n",
        "        return self.scale * normalizor * rce.mean()\n",
        "\n",
        "\n",
        "class NormalizedCrossEntropy(nn.Module):\n",
        "    def __init__(self, num_classes=10, scale=1.0):\n",
        "        super(NormalizedCrossEntropy, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        pred = F.log_softmax(pred, dim=1)\n",
        "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
        "        nce = -1 * torch.sum(label_one_hot * pred, dim=1) / (- pred.sum(dim=1))\n",
        "        return self.scale * nce.mean()\n",
        "\n",
        "\n",
        "class MeanAbsoluteError(nn.Module):\n",
        "    def __init__(self, num_classes=10, scale=1.0):\n",
        "        super(MeanAbsoluteError, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "        return\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
        "        mae = 1. - torch.sum(label_one_hot * pred, dim=1)\n",
        "        return self.scale * mae.mean()\n",
        "\n",
        "\n",
        "class NormalizedMeanAbsoluteError(nn.Module):\n",
        "    def __init__(self, num_classes=10, scale=1.0):\n",
        "        super(NormalizedMeanAbsoluteError, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "        return\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        label_one_hot = torch.nn.functional.one_hot(labels, self.num_classes).float().to(self.device)\n",
        "        normalizor = 1 / (2 * (self.num_classes - 1))\n",
        "        mae = 1. - torch.sum(label_one_hot * pred, dim=1)\n",
        "        return self.scale * normalizor * mae.mean()\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    '''\n",
        "        https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
        "    '''\n",
        "\n",
        "    def __init__(self, gamma=0.5, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha, (float, int)):\n",
        "            self.alpha = torch.Tensor([alpha, 1-alpha])\n",
        "        if isinstance(alpha, list):\n",
        "            self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim() > 2:\n",
        "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1, 2)                         # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1, input.size(2))    # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1, 1)\n",
        "\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = torch.autograd.Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type() != input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0, target.data.view(-1))\n",
        "            logpt = logpt * torch.autograd.Variable(at)\n",
        "\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()\n",
        "\n",
        "\n",
        "class NormalizedFocalLoss(nn.Module):\n",
        "    def __init__(self, scale=1.0, gamma=0, num_classes=10, alpha=None, size_average=True):\n",
        "        super(NormalizedFocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.size_average = size_average\n",
        "        self.num_classes = num_classes\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        target = target.view(-1, 1)\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        normalizor = torch.sum(-1 * (1 - logpt.data.exp()) ** self.gamma * logpt, dim=1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = torch.autograd.Variable(logpt.data.exp())\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        loss = self.scale * loss / normalizor\n",
        "\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()\n",
        "\n",
        "\n",
        "# losses done - 4 possible combinations below\n",
        "\n",
        "class NCEandRCE(torch.nn.Module):\n",
        "    def __init__(self, alpha, beta, num_classes=10):\n",
        "        super(NCEandRCE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.nce = NormalizedCrossEntropy(scale=alpha, num_classes=num_classes)\n",
        "        self.rce = ReverseCrossEntropy(scale=beta, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        return self.nce(pred, labels) + self.rce(pred, labels)\n",
        "\n",
        "\n",
        "class NCEandMAE(torch.nn.Module):\n",
        "    def __init__(self, alpha, beta, num_classes=10):\n",
        "        super(NCEandMAE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.nce = NormalizedCrossEntropy(scale=alpha, num_classes=num_classes)\n",
        "        self.mae = MeanAbsoluteError(scale=beta, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        return self.nce(pred, labels) + self.mae(pred, labels)\n",
        "\n",
        "\n",
        "class NFLandMAE(torch.nn.Module):\n",
        "    def __init__(self, alpha, beta, num_classes=10, gamma=0.5):\n",
        "        super(NFLandMAE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.nfl = NormalizedFocalLoss(scale=alpha, gamma=gamma, num_classes=num_classes)\n",
        "        self.mae = MeanAbsoluteError(scale=beta, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        return self.nfl(pred, labels) + self.mae(pred, labels)\n",
        "\n",
        "\n",
        "class NFLandRCE(torch.nn.Module):\n",
        "    def __init__(self, alpha, beta, num_classes=10, gamma=0.5):\n",
        "        super(NFLandRCE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.nfl = NormalizedFocalLoss(scale=alpha, gamma=gamma, num_classes=num_classes)\n",
        "        self.rce = ReverseCrossEntropy(scale=beta, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, pred, labels):\n",
        "        return self.nfl(pred, labels) + self.rce(pred, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nvkBFT0UlD2d"
      },
      "outputs": [],
      "source": [
        "# robust loss - MAE, RCE\n",
        "# normalized - NMAE, NRCE\n",
        "# non robust - CE, FL\n",
        "# made robust - NCE, NFL\n",
        "# active loss - NCE, NFL\n",
        "# passive loss - MAE, RCE\n",
        "# 4 possible combinations - NCE + MAE, NCE + RCE, NFL + MAE, NFL + RCE\n",
        "\n",
        "# Experiment 1 - robust(normalized) vs non robust test error\n",
        "# Experiment 2 - best alpha, beta for each combination\n",
        "# Experiment 3 - comparison across 4 possible combinations (best params of each)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3gmi2OO5p80N"
      },
      "outputs": [],
      "source": [
        "def add_symmetric_noise(labels, noise_ratio):\n",
        "    \"\"\"Flip labels randomly to incorrect ones for symmetric noise.\"\"\"\n",
        "    noisy_labels = labels.clone()\n",
        "    num_classes = len(np.unique(labels))\n",
        "    num_samples = len(labels)\n",
        "\n",
        "    # Randomly flip labels\n",
        "    for i in range(num_samples):\n",
        "        if np.random.rand() < noise_ratio:\n",
        "            # Randomly choose a new label that is different from the original\n",
        "            new_label = np.random.randint(0, num_classes)\n",
        "            while new_label == labels[i]:\n",
        "                new_label = np.random.randint(0, num_classes)\n",
        "            noisy_labels[i] = new_label\n",
        "\n",
        "    return noisy_labels\n",
        "\n",
        "\n",
        "def add_asymmetric_noise(labels, noise_ratio):\n",
        "    \"\"\"Flip labels within a specific set of classes for asymmetric noise.\"\"\"\n",
        "    noisy_labels = labels.clone()\n",
        "\n",
        "    # Noise map: Flip classes as defined by the user (example for CIFAR-10)\n",
        "    noise_map = {\n",
        "        0: [1, 2],  # Flip class 0 to class 1 or class 2\n",
        "        1: [2, 3],  # Flip class 1 to class 2 or class 3\n",
        "        2: [3, 4],  # Flip class 2 to class 3 or class 4\n",
        "        3: [4, 5],  # Flip class 3 to class 4 or class 5\n",
        "        4: [5, 6],  # Flip class 4 to class 5 or class 6\n",
        "        5: [6, 7],  # Flip class 5 to class 6 or class 7\n",
        "        6: [7, 8],  # Flip class 6 to class 7 or class 8\n",
        "        7: [8, 9],  # Flip class 7 to class 8 or class 9\n",
        "        8: [9, 0],  # Flip class 8 to class 9 or class 0\n",
        "        9: [0, 1],   # Flip class 9 to class 0 or class 1\n",
        "        10:[0,1]\n",
        "    }\n",
        "    num_samples = len(labels)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        if np.random.rand() < noise_ratio:\n",
        "            class_label = labels[i].item()\n",
        "            if class_label in noise_map:\n",
        "                new_label = np.random.choice(noise_map[class_label])\n",
        "                noisy_labels[i] = new_label\n",
        "\n",
        "    return noisy_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hnbQegswmGq0"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        if noise_type == 'symmetric':\n",
        "            y = add_symmetric_noise(y, noise_ratio)\n",
        "        elif noise_type == 'asymmetric':\n",
        "            y = add_asymmetric_noise(y, noise_ratio)\n",
        "        else:\n",
        "            pass\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]  lr: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return correct*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k08FiMlLFOwF"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "gamma = 0.5\n",
        "alpha = 1\n",
        "beta = 1\n",
        "loss_functions = [\n",
        "    CrossEntropy(num_classes=num_classes),\n",
        "    ReverseCrossEntropy(num_classes=num_classes, scale=1.0),\n",
        "    NormalizedReverseCrossEntropy(num_classes=num_classes, scale=1.0),\n",
        "    NormalizedCrossEntropy(num_classes=num_classes, scale=1.0),\n",
        "    MeanAbsoluteError(num_classes=num_classes, scale=1.0),\n",
        "    NormalizedMeanAbsoluteError(num_classes=num_classes, scale=1.0),\n",
        "    FocalLoss(gamma=gamma, alpha=None, size_average=True),\n",
        "    NormalizedFocalLoss(scale=1.0, gamma=gamma, num_classes=num_classes, alpha=None, size_average=True)\n",
        "]\n",
        "\n",
        "apl_loss_functions = [\n",
        "    NCEandRCE(alpha=alpha, beta=beta, num_classes=num_classes),\n",
        "    NCEandMAE(alpha=alpha, beta=beta, num_classes=num_classes),\n",
        "    NFLandMAE(alpha=alpha, beta=beta, num_classes=num_classes, gamma=gamma),\n",
        "    NFLandRCE(alpha=alpha, beta=beta, num_classes=num_classes, gamma=gamma)\n",
        "]\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uBgvd-8mkjG",
        "outputId": "899a7e8c-316a-4858-8180-25444b485793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Function: CrossEntropy(\n",
            "  (ce_loss): CrossEntropyLoss()\n",
            ")\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303738  [   64/50000]  lr: 0.010000\n",
            "loss: 2.300054  [ 6464/50000]  lr: 0.010000\n",
            "loss: 2.301407  [12864/50000]  lr: 0.010000\n",
            "loss: 2.302445  [19264/50000]  lr: 0.010000\n",
            "loss: 2.306779  [25664/50000]  lr: 0.010000\n",
            "loss: 2.304056  [32064/50000]  lr: 0.010000\n",
            "loss: 2.303227  [38464/50000]  lr: 0.010000\n",
            "loss: 2.302618  [44864/50000]  lr: 0.010000\n",
            "Test Error: \n",
            " Accuracy: 10.2%, Avg loss: 2.302203 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.302208  [   64/50000]  lr: 0.009755\n",
            "loss: 2.304506  [ 6464/50000]  lr: 0.009755\n",
            "loss: 2.305957  [12864/50000]  lr: 0.009755\n",
            "loss: 2.309018  [19264/50000]  lr: 0.009755\n",
            "loss: 2.296581  [25664/50000]  lr: 0.009755\n",
            "loss: 2.291424  [32064/50000]  lr: 0.009755\n",
            "loss: 2.323213  [38464/50000]  lr: 0.009755\n",
            "loss: 2.304954  [44864/50000]  lr: 0.009755\n",
            "Test Error: \n",
            " Accuracy: 23.0%, Avg loss: 2.193240 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.290988  [   64/50000]  lr: 0.009045\n",
            "loss: 2.257696  [ 6464/50000]  lr: 0.009045\n",
            "loss: 2.314983  [12864/50000]  lr: 0.009045\n",
            "loss: 2.262789  [19264/50000]  lr: 0.009045\n",
            "loss: 2.317470  [25664/50000]  lr: 0.009045\n",
            "loss: 2.274787  [32064/50000]  lr: 0.009045\n",
            "loss: 2.287944  [38464/50000]  lr: 0.009045\n",
            "loss: 2.244843  [44864/50000]  lr: 0.009045\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 2.167574 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.319139  [   64/50000]  lr: 0.007939\n",
            "loss: 2.292019  [ 6464/50000]  lr: 0.007939\n",
            "loss: 2.197506  [12864/50000]  lr: 0.007939\n",
            "loss: 2.242870  [19264/50000]  lr: 0.007939\n",
            "loss: 2.251233  [25664/50000]  lr: 0.007939\n",
            "loss: 2.315473  [32064/50000]  lr: 0.007939\n",
            "loss: 2.273736  [38464/50000]  lr: 0.007939\n",
            "loss: 2.261941  [44864/50000]  lr: 0.007939\n",
            "Test Error: \n",
            " Accuracy: 31.7%, Avg loss: 2.024009 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.272507  [   64/50000]  lr: 0.006545\n",
            "loss: 2.302418  [ 6464/50000]  lr: 0.006545\n",
            "loss: 2.215110  [12864/50000]  lr: 0.006545\n",
            "loss: 2.247427  [19264/50000]  lr: 0.006545\n",
            "loss: 2.303353  [25664/50000]  lr: 0.006545\n",
            "loss: 2.230572  [32064/50000]  lr: 0.006545\n",
            "loss: 2.236787  [38464/50000]  lr: 0.006545\n",
            "loss: 2.260770  [44864/50000]  lr: 0.006545\n",
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 2.019088 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.300906  [   64/50000]  lr: 0.005000\n",
            "loss: 2.180126  [ 6464/50000]  lr: 0.005000\n",
            "loss: 2.243728  [12864/50000]  lr: 0.005000\n",
            "loss: 2.283629  [19264/50000]  lr: 0.005000\n",
            "loss: 2.219361  [25664/50000]  lr: 0.005000\n",
            "loss: 2.257713  [32064/50000]  lr: 0.005000\n",
            "loss: 2.282703  [38464/50000]  lr: 0.005000\n",
            "loss: 2.167590  [44864/50000]  lr: 0.005000\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.976276 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.276767  [   64/50000]  lr: 0.003455\n",
            "loss: 2.212444  [ 6464/50000]  lr: 0.003455\n",
            "loss: 2.275659  [12864/50000]  lr: 0.003455\n",
            "loss: 2.290325  [19264/50000]  lr: 0.003455\n",
            "loss: 2.184501  [25664/50000]  lr: 0.003455\n",
            "loss: 2.240800  [32064/50000]  lr: 0.003455\n",
            "loss: 2.306436  [38464/50000]  lr: 0.003455\n",
            "loss: 2.244935  [44864/50000]  lr: 0.003455\n",
            "Test Error: \n",
            " Accuracy: 39.2%, Avg loss: 1.969348 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 2.172809  [   64/50000]  lr: 0.002061\n",
            "loss: 2.215627  [ 6464/50000]  lr: 0.002061\n",
            "loss: 2.222553  [12864/50000]  lr: 0.002061\n",
            "loss: 2.287386  [19264/50000]  lr: 0.002061\n",
            "loss: 2.238877  [25664/50000]  lr: 0.002061\n",
            "loss: 2.322626  [32064/50000]  lr: 0.002061\n",
            "loss: 2.276548  [38464/50000]  lr: 0.002061\n",
            "loss: 2.262319  [44864/50000]  lr: 0.002061\n",
            "Test Error: \n",
            " Accuracy: 41.1%, Avg loss: 1.927890 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2.209821  [   64/50000]  lr: 0.000955\n",
            "loss: 2.256691  [ 6464/50000]  lr: 0.000955\n",
            "loss: 2.186361  [12864/50000]  lr: 0.000955\n",
            "loss: 2.213007  [19264/50000]  lr: 0.000955\n",
            "loss: 2.123271  [25664/50000]  lr: 0.000955\n",
            "loss: 2.231466  [32064/50000]  lr: 0.000955\n",
            "loss: 2.186113  [38464/50000]  lr: 0.000955\n",
            "loss: 2.290422  [44864/50000]  lr: 0.000955\n",
            "Test Error: \n",
            " Accuracy: 42.4%, Avg loss: 1.909175 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.287858  [   64/50000]  lr: 0.000245\n",
            "loss: 2.283540  [ 6464/50000]  lr: 0.000245\n",
            "loss: 2.192227  [12864/50000]  lr: 0.000245\n",
            "loss: 2.220128  [19264/50000]  lr: 0.000245\n",
            "loss: 2.202682  [25664/50000]  lr: 0.000245\n",
            "loss: 2.226655  [32064/50000]  lr: 0.000245\n",
            "loss: 2.227810  [38464/50000]  lr: 0.000245\n",
            "loss: 2.268050  [44864/50000]  lr: 0.000245\n",
            "Test Error: \n",
            " Accuracy: 42.4%, Avg loss: 1.918504 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.262812  [   64/50000]  lr: 0.000000\n",
            "loss: 2.259379  [ 6464/50000]  lr: 0.000000\n",
            "loss: 2.247435  [12864/50000]  lr: 0.000000\n",
            "loss: 2.235295  [19264/50000]  lr: 0.000000\n",
            "loss: 2.161633  [25664/50000]  lr: 0.000000\n",
            "loss: 2.184877  [32064/50000]  lr: 0.000000\n",
            "loss: 2.270244  [38464/50000]  lr: 0.000000\n",
            "loss: 2.278946  [44864/50000]  lr: 0.000000\n",
            "Test Error: \n",
            " Accuracy: 42.4%, Avg loss: 1.918504 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.277591  [   64/50000]  lr: 0.000245\n",
            "loss: 2.263068  [ 6464/50000]  lr: 0.000245\n",
            "loss: 2.176640  [12864/50000]  lr: 0.000245\n",
            "loss: 2.248101  [19264/50000]  lr: 0.000245\n",
            "loss: 2.248428  [25664/50000]  lr: 0.000245\n",
            "loss: 2.194624  [32064/50000]  lr: 0.000245\n",
            "loss: 2.309505  [38464/50000]  lr: 0.000245\n",
            "loss: 2.224794  [44864/50000]  lr: 0.000245\n",
            "Test Error: \n",
            " Accuracy: 42.5%, Avg loss: 1.908093 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2.197237  [   64/50000]  lr: 0.000955\n",
            "loss: 2.147175  [ 6464/50000]  lr: 0.000955\n",
            "loss: 2.272411  [12864/50000]  lr: 0.000955\n",
            "loss: 2.219603  [19264/50000]  lr: 0.000955\n",
            "loss: 2.129848  [25664/50000]  lr: 0.000955\n",
            "loss: 2.327149  [32064/50000]  lr: 0.000955\n",
            "loss: 2.229635  [38464/50000]  lr: 0.000955\n",
            "loss: 2.232618  [44864/50000]  lr: 0.000955\n",
            "Test Error: \n",
            " Accuracy: 43.0%, Avg loss: 1.891302 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2.222405  [   64/50000]  lr: 0.002061\n",
            "loss: 2.220455  [ 6464/50000]  lr: 0.002061\n",
            "loss: 2.160393  [12864/50000]  lr: 0.002061\n",
            "loss: 2.205763  [19264/50000]  lr: 0.002061\n",
            "loss: 2.157174  [25664/50000]  lr: 0.002061\n",
            "loss: 2.342802  [32064/50000]  lr: 0.002061\n",
            "loss: 2.272166  [38464/50000]  lr: 0.002061\n",
            "loss: 2.190906  [44864/50000]  lr: 0.002061\n",
            "Test Error: \n",
            " Accuracy: 43.8%, Avg loss: 1.877109 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 2.190758  [   64/50000]  lr: 0.003455\n",
            "loss: 2.159858  [ 6464/50000]  lr: 0.003455\n",
            "loss: 2.268684  [12864/50000]  lr: 0.003455\n",
            "loss: 2.139011  [19264/50000]  lr: 0.003455\n",
            "loss: 2.208461  [25664/50000]  lr: 0.003455\n",
            "loss: 2.198686  [32064/50000]  lr: 0.003455\n",
            "loss: 2.252489  [38464/50000]  lr: 0.003455\n",
            "loss: 2.192698  [44864/50000]  lr: 0.003455\n",
            "Test Error: \n",
            " Accuracy: 40.9%, Avg loss: 1.923830 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2.210321  [   64/50000]  lr: 0.005000\n",
            "loss: 2.224145  [ 6464/50000]  lr: 0.005000\n",
            "loss: 2.211036  [12864/50000]  lr: 0.005000\n",
            "loss: 2.289769  [19264/50000]  lr: 0.005000\n",
            "loss: 2.260569  [25664/50000]  lr: 0.005000\n",
            "loss: 2.258968  [32064/50000]  lr: 0.005000\n",
            "loss: 2.184668  [38464/50000]  lr: 0.005000\n",
            "loss: 2.200487  [44864/50000]  lr: 0.005000\n",
            "Test Error: \n",
            " Accuracy: 43.4%, Avg loss: 1.817460 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2.381814  [   64/50000]  lr: 0.006545\n",
            "loss: 2.240618  [ 6464/50000]  lr: 0.006545\n",
            "loss: 2.105860  [12864/50000]  lr: 0.006545\n",
            "loss: 2.242735  [19264/50000]  lr: 0.006545\n",
            "loss: 2.253922  [25664/50000]  lr: 0.006545\n",
            "loss: 2.194327  [32064/50000]  lr: 0.006545\n",
            "loss: 2.167198  [38464/50000]  lr: 0.006545\n",
            "loss: 2.167801  [44864/50000]  lr: 0.006545\n",
            "Test Error: \n",
            " Accuracy: 46.6%, Avg loss: 1.866831 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2.279669  [   64/50000]  lr: 0.007939\n",
            "loss: 2.319324  [ 6464/50000]  lr: 0.007939\n",
            "loss: 2.123195  [12864/50000]  lr: 0.007939\n",
            "loss: 2.233268  [19264/50000]  lr: 0.007939\n",
            "loss: 2.128025  [25664/50000]  lr: 0.007939\n",
            "loss: 2.207665  [32064/50000]  lr: 0.007939\n",
            "loss: 2.168657  [38464/50000]  lr: 0.007939\n",
            "loss: 2.272058  [44864/50000]  lr: 0.007939\n",
            "Test Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.830944 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2.148656  [   64/50000]  lr: 0.009045\n",
            "loss: 2.164281  [ 6464/50000]  lr: 0.009045\n",
            "loss: 2.138361  [12864/50000]  lr: 0.009045\n",
            "loss: 2.214234  [19264/50000]  lr: 0.009045\n",
            "loss: 2.135490  [25664/50000]  lr: 0.009045\n",
            "loss: 2.244972  [32064/50000]  lr: 0.009045\n",
            "loss: 2.327277  [38464/50000]  lr: 0.009045\n",
            "loss: 2.176561  [44864/50000]  lr: 0.009045\n",
            "Test Error: \n",
            " Accuracy: 49.3%, Avg loss: 1.756636 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2.100449  [   64/50000]  lr: 0.009755\n",
            "loss: 2.177170  [ 6464/50000]  lr: 0.009755\n",
            "loss: 2.162389  [12864/50000]  lr: 0.009755\n",
            "loss: 2.355430  [19264/50000]  lr: 0.009755\n",
            "loss: 2.279921  [25664/50000]  lr: 0.009755\n",
            "loss: 2.270095  [32064/50000]  lr: 0.009755\n",
            "loss: 2.259711  [38464/50000]  lr: 0.009755\n",
            "loss: 2.218507  [44864/50000]  lr: 0.009755\n",
            "Test Error: \n",
            " Accuracy: 42.8%, Avg loss: 1.850167 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 2.198131  [   64/50000]  lr: 0.010000\n",
            "loss: 2.235555  [ 6464/50000]  lr: 0.010000\n",
            "loss: 2.083690  [12864/50000]  lr: 0.010000\n",
            "loss: 2.273039  [19264/50000]  lr: 0.010000\n",
            "loss: 2.221770  [25664/50000]  lr: 0.010000\n",
            "loss: 2.218672  [32064/50000]  lr: 0.010000\n",
            "loss: 2.174290  [38464/50000]  lr: 0.010000\n",
            "loss: 2.167295  [44864/50000]  lr: 0.010000\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 1.798738 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 2.153572  [   64/50000]  lr: 0.009755\n",
            "loss: 2.230332  [ 6464/50000]  lr: 0.009755\n",
            "loss: 2.109036  [12864/50000]  lr: 0.009755\n",
            "loss: 2.156411  [19264/50000]  lr: 0.009755\n",
            "loss: 2.311431  [25664/50000]  lr: 0.009755\n",
            "loss: 2.182618  [32064/50000]  lr: 0.009755\n",
            "loss: 2.131554  [38464/50000]  lr: 0.009755\n",
            "loss: 2.153963  [44864/50000]  lr: 0.009755\n",
            "Test Error: \n",
            " Accuracy: 55.8%, Avg loss: 1.735261 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 2.105271  [   64/50000]  lr: 0.009045\n",
            "loss: 2.195635  [ 6464/50000]  lr: 0.009045\n",
            "loss: 2.088865  [12864/50000]  lr: 0.009045\n",
            "loss: 2.059426  [19264/50000]  lr: 0.009045\n",
            "loss: 2.167895  [25664/50000]  lr: 0.009045\n",
            "loss: 2.246473  [32064/50000]  lr: 0.009045\n",
            "loss: 2.117057  [38464/50000]  lr: 0.009045\n",
            "loss: 2.226092  [44864/50000]  lr: 0.009045\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.718685 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 2.171905  [   64/50000]  lr: 0.007939\n",
            "loss: 2.259127  [ 6464/50000]  lr: 0.007939\n",
            "loss: 2.041486  [12864/50000]  lr: 0.007939\n",
            "loss: 2.214833  [19264/50000]  lr: 0.007939\n",
            "loss: 2.194732  [25664/50000]  lr: 0.007939\n",
            "loss: 2.185190  [32064/50000]  lr: 0.007939\n",
            "loss: 2.165992  [38464/50000]  lr: 0.007939\n",
            "loss: 2.221010  [44864/50000]  lr: 0.007939\n",
            "Test Error: \n",
            " Accuracy: 55.7%, Avg loss: 1.691421 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 2.184859  [   64/50000]  lr: 0.006545\n",
            "loss: 2.221865  [ 6464/50000]  lr: 0.006545\n",
            "loss: 2.177758  [12864/50000]  lr: 0.006545\n",
            "loss: 2.196810  [19264/50000]  lr: 0.006545\n",
            "loss: 2.246516  [25664/50000]  lr: 0.006545\n",
            "loss: 2.162528  [32064/50000]  lr: 0.006545\n",
            "loss: 2.248524  [38464/50000]  lr: 0.006545\n",
            "loss: 2.115448  [44864/50000]  lr: 0.006545\n",
            "Test Error: \n",
            " Accuracy: 58.6%, Avg loss: 1.680845 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 2.171065  [   64/50000]  lr: 0.005000\n",
            "loss: 2.050123  [ 6464/50000]  lr: 0.005000\n",
            "loss: 2.072912  [12864/50000]  lr: 0.005000\n",
            "loss: 2.196043  [19264/50000]  lr: 0.005000\n",
            "loss: 2.163550  [25664/50000]  lr: 0.005000\n",
            "loss: 2.257381  [32064/50000]  lr: 0.005000\n",
            "loss: 2.198557  [38464/50000]  lr: 0.005000\n",
            "loss: 2.151401  [44864/50000]  lr: 0.005000\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.633617 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 2.135306  [   64/50000]  lr: 0.003455\n",
            "loss: 2.193692  [ 6464/50000]  lr: 0.003455\n",
            "loss: 2.215460  [12864/50000]  lr: 0.003455\n",
            "loss: 2.104559  [19264/50000]  lr: 0.003455\n",
            "loss: 2.086465  [25664/50000]  lr: 0.003455\n",
            "loss: 2.253579  [32064/50000]  lr: 0.003455\n",
            "loss: 2.182116  [38464/50000]  lr: 0.003455\n",
            "loss: 2.118121  [44864/50000]  lr: 0.003455\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 1.575194 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 2.127036  [   64/50000]  lr: 0.002061\n",
            "loss: 2.109962  [ 6464/50000]  lr: 0.002061\n",
            "loss: 2.191012  [12864/50000]  lr: 0.002061\n",
            "loss: 2.146030  [19264/50000]  lr: 0.002061\n",
            "loss: 2.150303  [25664/50000]  lr: 0.002061\n",
            "loss: 2.270212  [32064/50000]  lr: 0.002061\n",
            "loss: 2.203820  [38464/50000]  lr: 0.002061\n",
            "loss: 2.249928  [44864/50000]  lr: 0.002061\n",
            "Test Error: \n",
            " Accuracy: 65.0%, Avg loss: 1.574772 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 2.146869  [   64/50000]  lr: 0.000955\n",
            "loss: 2.191986  [ 6464/50000]  lr: 0.000955\n",
            "loss: 2.117876  [12864/50000]  lr: 0.000955\n",
            "loss: 2.186676  [19264/50000]  lr: 0.000955\n",
            "loss: 2.107139  [25664/50000]  lr: 0.000955\n",
            "loss: 2.249829  [32064/50000]  lr: 0.000955\n",
            "loss: 2.254608  [38464/50000]  lr: 0.000955\n",
            "loss: 2.066321  [44864/50000]  lr: 0.000955\n",
            "Test Error: \n",
            " Accuracy: 65.5%, Avg loss: 1.549284 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 2.158211  [   64/50000]  lr: 0.000245\n",
            "loss: 2.068240  [ 6464/50000]  lr: 0.000245\n",
            "loss: 2.131820  [12864/50000]  lr: 0.000245\n",
            "loss: 2.107463  [19264/50000]  lr: 0.000245\n",
            "loss: 2.233711  [25664/50000]  lr: 0.000245\n",
            "loss: 2.194354  [32064/50000]  lr: 0.000245\n",
            "loss: 2.107494  [38464/50000]  lr: 0.000245\n",
            "loss: 2.180782  [44864/50000]  lr: 0.000245\n",
            "Test Error: \n",
            " Accuracy: 66.3%, Avg loss: 1.566552 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 2.069905  [   64/50000]  lr: 0.000000\n",
            "loss: 2.102223  [ 6464/50000]  lr: 0.000000\n",
            "loss: 2.151023  [12864/50000]  lr: 0.000000\n",
            "loss: 2.044578  [19264/50000]  lr: 0.000000\n",
            "loss: 2.095727  [25664/50000]  lr: 0.000000\n",
            "loss: 2.312626  [32064/50000]  lr: 0.000000\n"
          ]
        }
      ],
      "source": [
        "# Initialize model, optimizer, and loss function\n",
        "\n",
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = CrossEntropy(num_classes=num_classes)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfZwx2wfbwfD"
      },
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, and loss function\n",
        "\n",
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = NormalizedCrossEntropy(num_classes=num_classes, scale=1.0)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPJAZp3hcNYi"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = ReverseCrossEntropy(num_classes=num_classes, scale=1.0)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtPaW0ancUhF"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = NormalizedReverseCrossEntropy(num_classes=num_classes, scale=1.0)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsh0EekcbZ9"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = MeanAbsoluteError(num_classes=num_classes, scale=1.0)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ConGWjmfciu9"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = NormalizedMeanAbsoluteError(num_classes=num_classes, scale=1.0)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4BinN2FcmwF"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = FocalLoss(gamma=gamma, alpha=None, size_average=True)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J23y-25bcs70"
      },
      "outputs": [],
      "source": [
        "model = CNN8().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "loss_fn = NormalizedFocalLoss(scale=1.0, gamma=gamma, num_classes=num_classes, alpha=None, size_average=True)\n",
        "\n",
        "noise_type = \"symmetric\"\n",
        "noise_ratio = 0.6\n",
        "epochs = 120\n",
        "print(f\"Loss Function: {loss_fn}\")\n",
        "R = []\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, scheduler, noise_type, noise_ratio)\n",
        "    test_accuracy = test(test_dataloader, model, loss_fn)\n",
        "    R.append(test_accuracy)\n",
        "    scheduler.step()\n",
        "results.append(R)\n",
        "print(\"Done!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
